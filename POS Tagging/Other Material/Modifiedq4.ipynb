{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir,getcwd\n",
    "from os.path import isfile, join\n",
    "taggedText = []\n",
    "text = []\n",
    "filepath = join(getcwd(), \"browncopy\")\n",
    "allFiles = [f for f in listdir(filepath) if not (f.startswith('.')) and isfile(join(filepath, f))]\n",
    "for file in allFiles:\n",
    "    filename = join(filepath, file)\n",
    "    for line in open(filename,'r'):\n",
    "        if line != '\\n':\n",
    "            text.append(line.strip())\n",
    "#             start tag is <s> and end tag is <e>\n",
    "            taggedText.append('<s> ' + (line.strip()) + ' <e>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "wordTagDict = collections.Counter()\n",
    "unigramTagDict = collections.Counter()\n",
    "bigramTagDict = collections.Counter()\n",
    "for line in taggedText:\n",
    "    words=line.split(' ')\n",
    "    for wordIndex in range(1,len(words)):\n",
    "        previousWordTag = words[wordIndex-1]\n",
    "        currentWordTag = words[wordIndex]\n",
    "        previousWordTagArray = previousWordTag.split('/')\n",
    "        currentWordTagArray = currentWordTag.split('/')\n",
    "        previousWordTagArrayLength = len(previousWordTagArray)\n",
    "        currentWordTagArrayLength = len(currentWordTagArray)            \n",
    "        previousTag = previousWordTagArray[-1]\n",
    "        currentTag = currentWordTagArray[-1]\n",
    "#         any two words in between the line\n",
    "        if previousWordTagArrayLength > 1 and currentWordTagArrayLength >1:\n",
    "            wordTagDict[currentWordTag] +=1\n",
    "            unigramTagDict[currentTag] += 1\n",
    "            bigramTagDict[previousTag + ' ' + currentTag ] += 1\n",
    "#        previous word is start of line\n",
    "        elif previousWordTagArrayLength == 1 and currentWordTagArrayLength>1:\n",
    "            wordTagDict[currentWordTag] +=1\n",
    "            unigramTagDict[currentTag] += 1\n",
    "            unigramTagDict[previousWordTag] += 1\n",
    "            bigramTagDict[ previousWordTag + ' ' + currentTag ] += 1\n",
    "#         current word is end of line\n",
    "        elif previousWordTagArrayLength > 1 and currentWordTagArrayLength == 1:\n",
    "            bigramTagDict[previousTag + ' ' + currentWordTag ] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transitionProb = {}\n",
    "K=0.1\n",
    "for tagPair in bigramTagDict:\n",
    "    prevTag = tagPair.split(' ')[0]\n",
    "    transitionProb[tagPair] = (bigramTagDict[tagPair]+K)/(unigramTagDict[prevTag] + (K*len(bigramTagDict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emissionProb = {}\n",
    "K = 0.1\n",
    "for wordTag in wordTagDict:\n",
    "    tag = wordTag.split('/')[-1]\n",
    "    emissionProb[wordTag] = (wordTagDict[wordTag] + K)/(unigramTagDict[tag] + (K * len(wordTagDict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFileName = 'humor.txt'\n",
    "testFile =  open(testFileName,'r')\n",
    "testText = testFile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updatedText = ''\n",
    "for ch in range(0,len(testText)):\n",
    "    updatedText += testText[ch]\n",
    "    if testText[ch] == '.':\n",
    "        updatedText += '\\n'\n",
    "    if ch > 2 and (testText[ch] == '!' and testText[ch-2] == '!') or (testText[ch] == '?' and testText[ch-2] == '?' and\n",
    "                                                                      testText[ch+2] != ')'):\n",
    "        updatedText += '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testSentences = updatedText.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1057"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "len(testSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findTagsPerSentence(sentence):\n",
    "    index = sentence.split()\n",
    "    columns = list(unigramTagDict.keys())\n",
    "    df = pd.DataFrame(index = index, columns = columns)\n",
    "    bp = pd.DataFrame(index = index, columns = columns)\n",
    "    transitionVocab = len(bigramTagDict)\n",
    "    emissionVocab = len(wordTagDict)\n",
    "    for col in columns: \n",
    "        word = index[0]\n",
    "#         smoothing which returns a basic value in case of unknown words\n",
    "        basicTransitionProb = K / (unigramTagDict[col] + (K * transitionVocab))\n",
    "        basicEmissionProb = K / (wordTagDict[word] + (K * emissionVocab))\n",
    "        df.at[index[0],col] = transitionProb.get('<s> ' + col, basicTransitionProb) * emissionProb.get(word+'/'+col,basicEmissionProb)\n",
    "    for i in range(1,len(index)):\n",
    "        maxVal = 0.0\n",
    "        maxarg = float('NaN')\n",
    "        word = index[i]\n",
    "        for col in columns:\n",
    "            for colIndex in range(0,len(columns)):\n",
    "                basicTransitionProb = K / (unigramTagDict[colIndex] + (K * transitionVocab))\n",
    "                basicEmissionProb = K / (wordTagDict[word] + (K * emissionVocab))\n",
    "                previousTag = df.iloc[i-1,colIndex]\n",
    "                transProb = transitionProb.get(columns[colIndex] + ' ' + col, basicTransitionProb)\n",
    "                emisProb = emissionProb.get(word +'/'+col, basicEmissionProb)\n",
    "                checkMaxVal = previousTag * transProb * emisProb\n",
    "                if checkMaxVal == maxVal and maxarg is not float('NaN'):\n",
    "#                     selecting the most frequent tag in case of tie\n",
    "                    if unigramTagDict[maxarg] < unigramTagDict[columns[colIndex]]:\n",
    "                        maxarg = columns[colIndex]                   \n",
    "                if checkMaxVal > maxVal:\n",
    "                    maxVal = checkMaxVal\n",
    "                    maxarg = columns[colIndex]\n",
    "            df.at[index[i],col] = maxVal\n",
    "            bp.at[index[i],col] = maxarg\n",
    "    return df,bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  calculating tags from bp dict\n",
    "def generateTaggedSentence(df,bp,i):\n",
    "    tagDict = {}\n",
    "    taggedSentence = ' <EOS> \\n'\n",
    "    firstSentence = '<sentence ID='+ str(i+1) +'> \\n' \n",
    "#     finalSentence = ''\n",
    "    indx = list(df.index)\n",
    "    columns = list(df.columns)\n",
    "    maxVal = 0.0\n",
    "    maxArg = float('NaN')\n",
    "    lastWord = indx[-1]\n",
    "    lastWordIndex = len(indx)-1\n",
    "    for colIndex in range(0,len(columns)):\n",
    "        checkMaxVal = df.iloc[lastWordIndex,colIndex]\n",
    "        if checkMaxVal == maxVal and maxArg is not float('NaN'):\n",
    "    #                     selecting the most frequent tag in case of tie\n",
    "            if unigramTagDict[maxArg] < unigramTagDict[columns[colIndex]]:\n",
    "                maxArg = columns[colIndex]                   \n",
    "        if checkMaxVal > maxVal:\n",
    "            maxVal = checkMaxVal\n",
    "            maxArg = columns[colIndex]\n",
    "    lastArg = maxArg\n",
    "    taggedSentence = lastWord + ', ' + maxArg + '\\n' + taggedSentence\n",
    "    indexList = list(range(0,len(indx),1))\n",
    "    for j in indexList[::-1]:\n",
    "        if j is not len(indx)-1:\n",
    "            curArg = bp.iloc[j+1,columns.index(lastArg)]\n",
    "            sentence = indx[j] + ', ' + curArg + ' \\n '\n",
    "            taggedSentence = sentence + taggedSentence\n",
    "            lastArg = curArg\n",
    "    taggedSentence = firstSentence + taggedSentence\n",
    "    return taggedSentence   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on sentence number 92\n",
      "on sentence number 93\n",
      "on sentence number 94\n",
      "on sentence number 95\n",
      "on sentence number 96\n",
      "on sentence number 97\n",
      "on sentence number 98\n",
      "on sentence number 99\n",
      "on sentence number 100\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1835f3063ae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m92\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestSentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on sentence number '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindTagsPerSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestSentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtaggedSentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateTaggedSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'viterbi_after92.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d22db89acb68>\u001b[0m in \u001b[0;36mfindTagsPerSentence\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mbasicTransitionProb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0munigramTagDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolIndex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtransitionVocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mbasicEmissionProb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwordTagDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0memissionVocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mpreviousTag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mtransProb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransitionProb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolIndex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasicTransitionProb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0memisProb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memissionProb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasicEmissionProb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m             \u001b[0;31m# if the dim was reduced, then pass a lower-dim the next time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m                 \u001b[0maxis\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "#  viterbi algorithm\n",
    "for i in range(92,len(testSentences)):\n",
    "    print('on sentence number '+ str(i))\n",
    "    df,bp = findTagsPerSentence(testSentences[i])\n",
    "    taggedSentence = generateTaggedSentence(df,bp,i)\n",
    "    f = open('viterbi_after92.txt','a')\n",
    "    f.write(taggedSentence)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findTagsPerSentenceUsingList(sentence):\n",
    "    index = sentence.split()\n",
    "    columns = list(unigramTagDict.keys())\n",
    "    # Creates a list containing 5 lists, each of 8 items, all set to 0\n",
    "    colCount, rowCount = len(columns), len(index)\n",
    "    df = [[0 for x in range(colCount)] for y in range(rowCount)]\n",
    "    bp = [[0 for x in range(colCount)] for y in range(rowCount)]\n",
    "    \n",
    "# #     df = pd.DataFrame(index = index, columns = columns)\n",
    "# #     bp = pd.DataFrame(index = index, columns = columns)\n",
    "    transitionVocab = len(bigramTagDict)\n",
    "    emissionVocab = len(wordTagDict)\n",
    "\n",
    "    for col in columns: \n",
    "        word = index[0]\n",
    "#         smoothing which returns a basic value in case of unknown words\n",
    "        basicTransitionProb = K / (unigramTagDict[col] + (K * transitionVocab))\n",
    "        basicEmissionProb = K / (wordTagDict[word] + (K * emissionVocab))\n",
    "        df[0][columns.index(col)] = transitionProb.get('<s> ' + col, basicTransitionProb) * emissionProb.get(word+'/'+col,basicEmissionProb)\n",
    "#     return df\n",
    "    for i in range(1,len(index)):\n",
    "        maxVal = 0.0\n",
    "        maxarg = 0\n",
    "        word = index[i]\n",
    "        for col in columns:\n",
    "            for colIndex in range(0,len(columns)):\n",
    "                basicTransitionProb = K / (unigramTagDict[colIndex] + (K * transitionVocab))\n",
    "                basicEmissionProb = K / (wordTagDict[word] + (K * emissionVocab))\n",
    "                previousTag = df[i-1][colIndex]\n",
    "                transProb = transitionProb.get(columns[colIndex] + ' ' + col, basicTransitionProb)\n",
    "                emisProb = emissionProb.get(word +'/'+col, basicEmissionProb)\n",
    "                checkMaxVal = previousTag * transProb * emisProb\n",
    "#                 if checkMaxVal == maxVal and maxarg is not float('NaN'):\n",
    "# #                     selecting the most frequent tag in case of tie\n",
    "#                     if unigramTagDict[maxarg] < unigramTagDict[columns[colIndex]]:\n",
    "#                         maxarg = colIndex\n",
    "                if checkMaxVal > maxVal:\n",
    "                    maxVal = checkMaxVal\n",
    "                    maxarg = colIndex\n",
    "            df[i][columns.index(col)] = maxVal\n",
    "            bp[i][columns.index(col)] = maxarg\n",
    "    return df,bp, index, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  calculating tags from bp dict\n",
    "def generateTaggedSentenceUsingList(df,bp, index, columns,i):\n",
    "    tagDict = {}\n",
    "    taggedSentence = ' <EOS> \\n'\n",
    "    firstSentence = '<sentence ID='+ str(i+1) +'> \\n' \n",
    "#     finalSentence = ''\n",
    "    indx = index\n",
    "#     columns = list(df.columns)\n",
    "    maxVal = 0.0\n",
    "    maxArg = 0\n",
    "    lastWord = indx[-1]\n",
    "    lastWordIndex = len(indx)-1\n",
    "    for colIndex in range(0,len(columns)):\n",
    "        checkMaxVal = df[lastWordIndex][colIndex]                  \n",
    "        if checkMaxVal > maxVal:\n",
    "            maxVal = checkMaxVal\n",
    "            maxArg = colIndex\n",
    "    lastArg = maxArg\n",
    "    taggedSentence = lastWord + ', ' + columns[maxArg] + '\\n' + taggedSentence\n",
    "    indexList = list(range(0,len(indx),1))\n",
    "    for j in indexList[::-1]:\n",
    "        if j is not len(indx)-1:\n",
    "            curArg = bp[j+1][lastArg]\n",
    "            sentence = indx[j] + ', ' + columns[curArg] + ' \\n '\n",
    "            taggedSentence = sentence + taggedSentence\n",
    "            lastArg = curArg\n",
    "    taggedSentence = firstSentence + taggedSentence\n",
    "    return taggedSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df,bp,index,columns = findTagsPerSentenceUsingList(testSentences[18])\n",
    "taggedSentence = generateTaggedSentenceUsingList(df,bp,index, columns, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sentence ID=19> \\nWelch, pps \\n wanted, qlp \\n to, to \\n know, dt+bez \\n why, ) \\n ., .\\n <EOS> \\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggedSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "d['a'] = 3\n",
    "d['b'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(d, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149903"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(unigramTagDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Counter' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1171fb57ef9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munigramTagDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Counter' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "max(unigramTagDict.iteritems(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started sentence 70\n",
      "Started sentence 71\n",
      "Started sentence 72\n",
      "Started sentence 73\n",
      "Started sentence 74\n",
      "Started sentence 75\n",
      "Started sentence 76\n",
      "Started sentence 77\n",
      "Started sentence 78\n",
      "Started sentence 79\n",
      "Started sentence 80\n",
      "Started sentence 81\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e557bb0bee34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestSentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Started sentence '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindTagsPerSentenceUsingList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestSentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtaggedSentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateTaggedSentenceUsingList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'viterbi_after70.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-a7ab74bafb62>\u001b[0m in \u001b[0;36mfindTagsPerSentenceUsingList\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mpreviousTag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mtransProb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransitionProb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolIndex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasicTransitionProb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0memisProb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memissionProb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasicEmissionProb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mcheckMaxVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreviousTag\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtransProb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0memisProb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#                 if checkMaxVal == maxVal and maxarg is not float('NaN'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  viterbi algorithm\n",
    "for i in range(70,len(testSentences)):\n",
    "    print('Started sentence '+ str(i))\n",
    "    df,bp, index, columns = findTagsPerSentenceUsingList(testSentences[i])\n",
    "    taggedSentence = generateTaggedSentenceUsingList(df,bp, index, columns, i)\n",
    "    f = open('viterbi_after70.txt','a')\n",
    "    f.write(taggedSentence)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1057"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
