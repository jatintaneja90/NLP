{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Parse Training data and find wordTag count, unigram count and bigram count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir,getcwd\n",
    "from os.path import isfile, join\n",
    "taggedText = []\n",
    "text = []\n",
    "filepath = join(getcwd(), \"browncopy\")\n",
    "allFiles = [f for f in listdir(filepath) if not (f.startswith('.')) and isfile(join(filepath, f))]\n",
    "for file in allFiles:\n",
    "    filename = join(filepath, file)\n",
    "    for line in open(filename,'r'):\n",
    "        if line != '\\n':\n",
    "            text.append(line.strip())\n",
    "#             start tag is <s> and end tag is <e>\n",
    "            taggedText.append('<s> ' + (line.strip()) + ' <e>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "wordTagDict = collections.Counter()\n",
    "unigramTagDict = collections.Counter()\n",
    "bigramTagDict = collections.Counter()\n",
    "for line in taggedText:\n",
    "    words=line.split(' ')\n",
    "    for wordIndex in range(1,len(words)):\n",
    "        previousWordTag = words[wordIndex-1]\n",
    "        currentWordTag = words[wordIndex]\n",
    "        previousWordTagArray = previousWordTag.split('/')\n",
    "        currentWordTagArray = currentWordTag.split('/')\n",
    "        previousWordTagArrayLength = len(previousWordTagArray)\n",
    "        currentWordTagArrayLength = len(currentWordTagArray)            \n",
    "        previousTag = previousWordTagArray[-1]\n",
    "        currentTag = currentWordTagArray[-1]\n",
    "#         any two words in between the line\n",
    "        if previousWordTagArrayLength > 1 and currentWordTagArrayLength >1:\n",
    "            wordTagDict[currentWordTag] +=1\n",
    "            unigramTagDict[currentTag] += 1\n",
    "            bigramTagDict[previousTag + ' ' + currentTag ] += 1\n",
    "#        previous word is start of line\n",
    "        elif previousWordTagArrayLength == 1 and currentWordTagArrayLength>1:\n",
    "            wordTagDict[currentWordTag] +=1\n",
    "            unigramTagDict[currentTag] += 1\n",
    "            unigramTagDict[previousWordTag] += 1\n",
    "            bigramTagDict[ previousWordTag + ' ' + currentTag ] += 1\n",
    "#         current word is end of line\n",
    "        elif previousWordTagArrayLength > 1 and currentWordTagArrayLength == 1:\n",
    "            bigramTagDict[previousTag + ' ' + currentWordTag ] += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing wordTag count, unigram count and bigram count output to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordTagText = ''\n",
    "for wordTag in wordTagDict:\n",
    "    wordTagText += wordTag + ' : ' + str(wordTagDict[wordTag]) + '\\n'\n",
    "unigramTagText = ''\n",
    "for unigramTag in unigramTagDict:\n",
    "    unigramTagText += unigramTag + ' : ' + str(unigramTagDict[unigramTag]) + '\\n'\n",
    "bigramTagText = ''\n",
    "for bigramTag in bigramTagDict:\n",
    "    bigramTagText += bigramTag + ' : ' + str(bigramTagDict[bigramTag]) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Commented out this code to avoid appending values again\n",
    "# f = open('wordtagCounts.txt','a')\n",
    "# f.write(wordTagText)\n",
    "# f.close()\n",
    "# f = open('unigramtagCounts.txt','a')\n",
    "# f.write(unigramTagText)\n",
    "# f.close()\n",
    "# f = open('bigramtagCounts.txt','a')\n",
    "# f.write(bigramTagText)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Calculate transition probablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transitionProb = {}\n",
    "K=0.1\n",
    "for tagPair in bigramTagDict:\n",
    "    prevTag = tagPair.split(' ')[0]\n",
    "    transitionProb[tagPair] = (bigramTagDict[tagPair]+K)/(unigramTagDict[prevTag] + (K*len(bigramTagDict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Calculate emission probablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emissionProb = {}\n",
    "K = 0.1\n",
    "for wordTag in wordTagDict:\n",
    "    tag = wordTag.split('/')[-1]\n",
    "    emissionProb[wordTag] = (wordTagDict[wordTag] + K)/(unigramTagDict[tag] + (K * len(wordTagDict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output transition and emission probablity to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transitionText = ''\n",
    "for transitionTagPair in transitionProb:\n",
    "    transitionText += transitionTagPair + ' : ' + str(transitionProb[transitionTagPair]) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emissionText = ''\n",
    "for emissionPair in emissionProb:\n",
    "    emissionText += emissionPair + ' : ' + str(emissionProb[emissionPair]) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Commented out this code to avoid appending values again\n",
    "# f = open('transitionProb.txt','a')\n",
    "# f.write(transitionText)\n",
    "# f.close()\n",
    "# f = open('emissionProb.txt','a')\n",
    "# f.write(emissionText)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 Generate sentences using HMM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s> I/ppss represents/vbz hall/nn-hl Need/nn-hl of/in-hl Norms/nns-hl meteorites/nns-hl in/in-hl in/in-hl an/at-hl A/at-hl The/at-hl the/at-hl the/at-hl dream/nn-hl warfare/nn-hl co-optation/nn-hl iodine/nn-hl off/rp-hl <e> 1.0812655701071951e-85\n",
      "\n",
      "\n",
      "<s> Quint/np limitations/nns intervals/nns ,/, I/ppss you/ppss sent/vbd his/pp$ his/pp$ poems/nns effect/nn measurements/nns article/nn and/cc &/cc-tl Government/nn-tl Tumor/nn-tl Island/nn-tl President/nn-tl ./. <e> 1.070531057195176e-62\n",
      "\n",
      "\n",
      "<s> 2/cd-hl <e> 3.853427882184323e-05\n",
      "\n",
      "\n",
      "<s> a/at appreciated/vbd Santa/np Manchester/np-tl Chicago/np-tl Figure/nn-tl Morris/np-tl Sherman's/np$ expressivness/nn or/cc elementary/jj question/nn what/wdt-hl which/wdt He/pps Did/dod did/dod did/dod did/dod didn't/dod* did/dod didn't/dod* didn't/dod* written/vbn a/at mat/nn start/nn must/md a/at-hl An/at-hl the/at-hl method/nn-hl chemical/nn-hl water/nn-hl device/nn-hl Life/nn-hl of/in-hl of/in-hl in/in-hl of/in-hl the/at-hl portrayed/vbn-hl ./.-hl ?/.-hl <e> 4.029490713778099e-169\n",
      "\n",
      "\n",
      "<s> when/wrb ?/. <e> 5.1373250926109715e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(0,5):\n",
    "    firstTag = '<s>'\n",
    "    secondTag = ''\n",
    "    sentenceProb = 1\n",
    "    sentence = firstTag + ' '\n",
    "    while True:\n",
    "        tagPairList = []\n",
    "        wordTagList = []\n",
    "        wordTagProbList = []\n",
    "        tagPairProbList = []\n",
    "        wordTagGenDict = {}\n",
    "        tagPairGenDict = {}\n",
    "        for tagPair in bigramTagDict:\n",
    "            if firstTag in tagPair:\n",
    "                tagPairGenDict[tagPair] = bigramTagDict[tagPair]\n",
    "        totalTagPairs = sum(tagPairGenDict.values())\n",
    "        for tagPair in tagPairGenDict:\n",
    "            tagPairGenDict[tagPair] = tagPairGenDict[tagPair]/totalTagPairs\n",
    "            tagPairList.append(tagPair)\n",
    "            tagPairProbList.append(tagPairGenDict[tagPair])\n",
    "            \n",
    "        curTagPair = np.random.choice(tagPairList, p=tagPairProbList)\n",
    "        secondTag = curTagPair.split(' ')[1]\n",
    "        if secondTag == '<e>':\n",
    "            sentence += secondTag\n",
    "            break;\n",
    "        for wordTag in wordTagDict:\n",
    "            if secondTag in wordTag:\n",
    "                wordTagGenDict[wordTag] = wordTagDict[wordTag]\n",
    "        totalWordTags = sum(wordTagGenDict.values())\n",
    "        \n",
    "        for wordTag in wordTagGenDict:\n",
    "            wordTagGenDict[wordTag] = wordTagGenDict[wordTag]/totalWordTags\n",
    "            wordTagList.append(wordTag)\n",
    "            wordTagProbList.append(wordTagGenDict[wordTag])\n",
    "        curWordTag = np.random.choice(wordTagList, p=wordTagProbList)\n",
    "        sentenceProb *= transitionProb[curTagPair] * emissionProb[curWordTag]\n",
    "        sentence += curWordTag + ' '\n",
    "        firstTag = secondTag\n",
    "    print('\\n')\n",
    "    print(sentence + ' ' + str(sentenceProb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "4.5 Using viterbi algorithm tag each word in humor.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFileName = 'humor.txt'\n",
    "testFile =  open(testFileName,'r')\n",
    "testText = testFile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updatedText = ''\n",
    "for ch in range(0,len(testText)):\n",
    "    updatedText += testText[ch]\n",
    "    if testText[ch] == '.':\n",
    "        updatedText += '\\n'\n",
    "    if ch > 2 and (testText[ch] == '!' and testText[ch-2] == '!') or (testText[ch] == '?' and testText[ch-2] == '?' and\n",
    "                                                                      testText[ch+2] != ')'):\n",
    "        updatedText += '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testSentences = updatedText.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was among these that Hinkle identified a photograph of Barco ! !'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findTagsPerSentenceUsingList(sentence):\n",
    "    index = sentence.split()\n",
    "    columns = list(unigramTagDict.keys())\n",
    "    colCount, rowCount = len(columns), len(index)\n",
    "    df = [[0 for x in range(colCount)] for y in range(rowCount)]\n",
    "    bp = [[0 for x in range(colCount)] for y in range(rowCount)]\n",
    "    transitionVocab = len(bigramTagDict)\n",
    "    emissionVocab = len(wordTagDict)\n",
    "\n",
    "    for col in columns: \n",
    "        word = index[0]\n",
    "#         smoothing which returns a basic value in case of unknown words\n",
    "        basicTransitionProb = K / (unigramTagDict[col] + (K * transitionVocab))\n",
    "        basicEmissionProb = K / (wordTagDict[word] + (K * emissionVocab))\n",
    "        df[0][columns.index(col)] = transitionProb.get('<s> ' + col, basicTransitionProb) * emissionProb.get(word+'/'+col,basicEmissionProb)\n",
    "    for i in range(1,len(index)):\n",
    "        maxVal = 0.0\n",
    "        maxarg = 0\n",
    "        word = index[i]\n",
    "        for col in columns:\n",
    "            for colIndex in range(0,len(columns)):\n",
    "                basicTransitionProb = K / (unigramTagDict[colIndex] + (K * transitionVocab))\n",
    "                basicEmissionProb = K / (wordTagDict[word] + (K * emissionVocab))\n",
    "                previousTag = df[i-1][colIndex]\n",
    "                transProb = transitionProb.get(columns[colIndex] + ' ' + col, basicTransitionProb)\n",
    "                emisProb = emissionProb.get(word +'/'+col, basicEmissionProb)\n",
    "                checkMaxVal = previousTag * transProb * emisProb\n",
    "                if checkMaxVal > maxVal:\n",
    "                    maxVal = checkMaxVal\n",
    "                    maxarg = colIndex\n",
    "            df[i][columns.index(col)] = maxVal\n",
    "            bp[i][columns.index(col)] = maxarg\n",
    "    return df,bp, index, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateTaggedSentenceUsingList(df,bp, index, columns,i):\n",
    "    tagDict = {}\n",
    "    taggedSentence = ' <EOS> \\n'\n",
    "    firstSentence = '<sentence ID='+ str(i+1) +'> \\n' \n",
    "    indx = index\n",
    "    maxVal = 0.0\n",
    "    maxArg = 0\n",
    "    lastWord = indx[-1]\n",
    "    lastWordIndex = len(indx)-1\n",
    "    for colIndex in range(0,len(columns)):\n",
    "        checkMaxVal = df[lastWordIndex][colIndex]                  \n",
    "        if checkMaxVal > maxVal:\n",
    "            maxVal = checkMaxVal\n",
    "            maxArg = colIndex\n",
    "    lastArg = maxArg\n",
    "    taggedSentence = lastWord + ', ' + columns[maxArg] + '\\n' + taggedSentence\n",
    "    indexList = list(range(0,len(indx),1))\n",
    "    for j in indexList[::-1]:\n",
    "        if j is not len(indx)-1:\n",
    "            curArg = bp[j+1][lastArg]\n",
    "            sentence = indx[j] + ', ' + columns[curArg] + ' \\n '\n",
    "            taggedSentence = sentence + taggedSentence\n",
    "            lastArg = curArg\n",
    "    taggedSentence = firstSentence + taggedSentence\n",
    "    return taggedSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  viterbi algorithm\n",
    "for i in range(0,len(testSentences)):\n",
    "    if testSentences[i] != '':\n",
    "        df,bp, index, columns = findTagsPerSentenceUsingList(testSentences[i])\n",
    "        taggedSentence = generateTaggedSentenceUsingList(df,bp, index, columns, i)\n",
    "        f = open('viterbiOutput.txt','a')\n",
    "        f.write(taggedSentence)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
