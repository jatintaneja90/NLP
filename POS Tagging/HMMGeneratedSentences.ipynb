{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a 5-gram character language model from the English training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir,getcwd\n",
    "from os.path import join, isfile\n",
    "import collections\n",
    "train4GramDict = collections.Counter()\n",
    "train5GramDict = collections.Counter()\n",
    "unigramDict = collections.Counter()\n",
    "filepath = join(getcwd(), \"gutenberg\")\n",
    "allFiles = [f for f in listdir(filepath) if not (f.startswith('.')) and isfile(join(filepath, f))]\n",
    "for file in allFiles: \n",
    "    trainText = ''\n",
    "    filename = join(filepath, file)\n",
    "    for line in open(filename,'r+', encoding=\"latin1\"):\n",
    "    #         removing empty line\n",
    "        if line != '\\n':\n",
    "            newLine = ''\n",
    "            for ch in range(0,len(line)):\n",
    "    # continuos space would get ignore\n",
    "                if line[ch] == '\\t':\n",
    "                    newLine+=' '\n",
    "                if ch != len(line)-1 and line[ch] == ' ' and line[ch] == line[ch+1]:\n",
    "                    continue;\n",
    "    #             in case of \\n , replace it with space\n",
    "                elif line[ch] == '\\n':\n",
    "                      newLine+=' '\n",
    "    #             add any other character\n",
    "                else:\n",
    "                    newLine+=line[ch]\n",
    "            trainText += newLine\n",
    "    \n",
    "    for charPos in range(0,len(trainText)):\n",
    "        unigramDict[trainText[charPos]] +=1\n",
    "    for charPos in range(0,len(trainText)-4):\n",
    "        key = trainText[charPos:charPos+4]\n",
    "        train4GramDict[key] +=1\n",
    "    for charPos in range(0,len(trainText)-5):\n",
    "        key = trainText[charPos:charPos+5]\n",
    "        train5GramDict[key] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11651645\n",
      "11651664\n"
     ]
    }
   ],
   "source": [
    "# report the 4-gram and 5-gram character counts\n",
    "print(sum(train5GramDict.values()))\n",
    "print(sum(train4GramDict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 5\n",
    "keysToDelete4Gram = []\n",
    "train4GramDict['UNK'] = 0\n",
    "for key in train4GramDict.keys():\n",
    "    if key is not 'UNK' and train4GramDict[key] < threshold:\n",
    "        train4GramDict['UNK'] += train4GramDict[key]\n",
    "        keysToDelete4Gram.append(key)\n",
    "for key in keysToDelete4Gram:\n",
    "    del train4GramDict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keysToDelete5Gram = []\n",
    "train5GramDict['UNK'] = 0\n",
    "for key in train5GramDict.keys():\n",
    "    if key is not 'UNK' and train5GramDict[key] < threshold:\n",
    "        train5GramDict['UNK'] += train5GramDict[key]\n",
    "        keysToDelete5Gram.append(key)\n",
    "for key in keysToDelete5Gram:\n",
    "    del train5GramDict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Report the average perplexity(per character) for file '03302_02.txt'. Use add-lambda smoothing (with lambda = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  processing the test file\n",
    "from os import listdir,getcwd\n",
    "from os.path import join\n",
    "testText = ''\n",
    "testFilepath = join(getcwd(), \"SOC\")\n",
    "testFilename = join(testFilepath, '03302_02.txt')\n",
    "for line in open(testFilename,'r+', encoding=\"latin1\"):\n",
    "#  removing empty line\n",
    "    if line != '\\n':\n",
    "        newLine = ''\n",
    "        for ch in range(0,len(line)):\n",
    "# continuos space would get ignore\n",
    "            if line[ch] == '\\t':\n",
    "                newLine+=' '\n",
    "            if ch != len(line)-1 and line[ch] == ' ' and line[ch] == line[ch+1]:\n",
    "                continue;\n",
    "#             in case of \\n , replace it with space\n",
    "            elif line[ch] == '\\n':\n",
    "                  newLine+=' '\n",
    "#             add any other character\n",
    "            else:\n",
    "                newLine+=line[ch]\n",
    "\n",
    "        testText += newLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6205262"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test5Grams = []\n",
    "for charPos in range(0,len(testText)-5):\n",
    "    test5Grams.append(testText[charPos:charPos+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6205257"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test5Grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, exp\n",
    "modelLogProb = 0\n",
    "K = 0.1\n",
    "vocabSize = len(unigramDict)\n",
    "N=len(test5Grams)\n",
    "for gram5 in test5Grams:\n",
    "    val5 = train5GramDict.get(gram5,None)\n",
    "    gram4 = ''\n",
    "    for ch in range(0,len(gram5)-1):\n",
    "        gram4 += gram5[ch]\n",
    "    val4 = train4GramDict.get(gram4,None)\n",
    "    if val5 is None:\n",
    "        val5 = train5GramDict['UNK']\n",
    "    if val4 is None:\n",
    "        val4 = train4GramDict['UNK']\n",
    "    logProb = log((val5 + K)/(val4 + (K * vocabSize)))\n",
    "    modelLogProb += logProb\n",
    "perplexity = exp(modelLogProb * (-1/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6028679391499376"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2927606.040980314"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLogProb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 report the names and scores of the three files with the highest perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perplexityDict = {}\n",
    "#  processing the test file\n",
    "from os import listdir,getcwd\n",
    "from os.path import join\n",
    "from math import expm1,log, exp\n",
    "testFilepath = join(getcwd(), \"SOC\")\n",
    "allFiles = [f for f in listdir(testFilepath) if not (f.startswith('.')) and isfile(join(testFilepath, f))]\n",
    "for file in allFiles:\n",
    "    testFilename = join(testFilepath, file)\n",
    "    testText = ''\n",
    "    for line in open(testFilename,'r+', encoding=\"latin1\"):\n",
    "    #  removing empty line\n",
    "        if line != '\\n':\n",
    "            newLine = ''\n",
    "            for ch in range(0,len(line)):\n",
    "    # continuos space would get ignore\n",
    "                if line[ch] == '\\t':\n",
    "                    newLine+=' '\n",
    "                if ch != len(line)-1 and line[ch] == ' ' and line[ch] == line[ch+1]:\n",
    "                    continue;\n",
    "    #             in case of \\n , replace it with space\n",
    "                elif line[ch] == '\\n':\n",
    "                      newLine+=' '\n",
    "    #             add any other character\n",
    "                else:\n",
    "                    newLine+=line[ch]\n",
    "\n",
    "            testText += newLine\n",
    "#     computing 5 grams of text\n",
    "    test5Grams = []\n",
    "    for charPos in range(0,len(testText)-5):\n",
    "        test5Grams.append(testText[charPos:charPos+5])\n",
    "#     computing file perplexity\n",
    "    fileLogProb = 0\n",
    "    K = 0.1\n",
    "    vocabSize = len(unigramDict)\n",
    "    N=len(test5Grams)\n",
    "    for gram5 in test5Grams:\n",
    "        val5 = train5GramDict.get(gram5,None)\n",
    "        gram4 = ''\n",
    "        for ch in range(0,len(gram5)-1):\n",
    "            gram4 += gram5[ch]\n",
    "        val4 = train4GramDict.get(gram4,None)\n",
    "        if val5 is None:\n",
    "            val5 = train5GramDict['UNK']\n",
    "        if val4 is None:\n",
    "            val4 = train4GramDict['UNK']\n",
    "        logProb = log((val5 + K)/(val4 + (K * vocabSize)))\n",
    "        fileLogProb += logProb\n",
    "    perplexity = exp(fileLogProb * (-1/N))\n",
    "    perplexityDict[file] = perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00101_01.txt 1.9651509541498489\n",
      "00503_01.txt 1.8550437262621398\n",
      "02803_02.txt 1.8076324619559627\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for key, value in sorted(perplexityDict.items(), key=lambda x:x[1], reverse=True):\n",
    "    if i<3:\n",
    "        i+=1\n",
    "        print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
